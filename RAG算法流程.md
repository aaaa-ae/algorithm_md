# 一、训练过程

RAG训练算法流程文字描述：

1、RAG-Sequence:给定输入<q, a>给定问题-答案对，rag先使用文档编码器把外部库的所有文档向量化，使用查询编码器把查询向量化，计算内积，取前k个最大的内积对应的文档作为非参数化内存，然后把查询和每篇文档拼接，输入生成器，生成一个输出（每篇文档都要生成一个序列输出），这个输出形状是（batch_size, step, vocab_num）,所以根据第三维度，可以很方便计算出想要输出标准答案的概率，每个文档都做上述相同的处理，最后根据这些概率和文档概率结合计算加权和，再取负对数作为损失函数（先求和，再取负对数），进行反向传递并调整参数（固定文档编码器，只调整查询编码器和生成器）

2、RAG-Token: 给定输入 <q, a> 问题-答案对，RAG先使用文档编码器把外部库的所有文档向量化，使用查询编码器把查询向量化，计算内积，取前k个最大的内积对应的文档作为非参数化内存。然后，在预测答案的每一个token时，将前一个token、查询q和每一篇文档拼接，输入生成器，生成一个下一个token的输出分布（即每一篇文档都要输出一个下一个token的输出分布），这个输出的形状是 (batch_size, vocab_num)。然后根据第三维度，找到标准答案里当前这个词对应的概率，接着用文档概率对这些“当前词概率”计算加权和，得到当前时间步的综合概率。对答案序列中的每一个token，都重复上述“为每个文档计算概率再加权和”的过程，得到每一个时间步的综合概率。最后，将每一个时间步的综合概率取负对数，再将这些负对数损失累加起来，得到总损失，进行反向传递并调整参数（固定文档编码器，只调整查询编码器和生成器）。

# RAG 训练流程总结

RAG (Retrieval-Augmented Generation) 的训练有两种主要变体：**RAG-Sequence** 和 **RAG-Token**。  
二者的区别在于“边际化 (marginalization)”发生的位置：前者在**序列级别**，后者在**token 级别**。

---

## 1. RAG-Sequence

**输入**：一个问题-答案对<q, a > 

**训练流程**：
1. **文档向量化**：使用固定的文档编码器对外部知识库中的所有文档向量化，并构建索引。  
2. **检索**：将查询 $q$ 输入查询编码器，得到查询向量 $\mathbf{q}$，并通过最大内积搜索 (MIPS) 检索出 Top-K 文档 $z_1, z_2, ..., z_K$。  
   - 检索概率由 softmax 内积得到：  
     $$
     p_\eta(z_i \mid q) = \frac{\exp(\mathbf{q}^\top \mathbf{d}(z_i))}{\sum_j \exp(\mathbf{q}^\top \mathbf{d}(z_j))}
     $$
3. **生成评估**：对于每个文档 $z_i$，拼接 $(q, z_i)$ 作为输入，交给生成器 (如 BART/T5)。生成器输出一个三维概率张量，形状为：  
   $$
   (\text{batch\_size}, \text{seq\_len}, \text{vocab\_size})
   $$
   根据标准答案 $a = (a_1, a_2, ..., a_N)$，逐 token 查找对应的概率并连乘：  
   $$
   p_\theta(a \mid q, z_i) = \prod_{t=1}^N p_\theta(a_t \mid q, z_i, a_{<t})
   $$
4. **边际化**：在序列级别，对不同文档的生成概率做加权和：  
   $$
   p(a \mid q) = \sum_{i=1}^K p_\eta(z_i \mid q) \cdot p_\theta(a \mid q, z_i)
   $$
5. **损失函数**：对整体概率取负对数：  
   $$
   \mathcal{L} = -\log p(a \mid q)
   $$
   并反向传播，更新查询编码器与生成器参数（文档编码器保持固定）。

---

## 2. RAG-Token

**输入**：一个问题-答案对 $\langle q, a \rangle$  

**训练流程**：
1. **文档向量化与检索**：与 RAG-Sequence 相同，使用固定的文档编码器得到向量索引，并用查询编码器检索 Top-K 文档。  
2. **逐 token 生成**：在生成答案的每个时间步 $t$，对每篇文档 $z_i$，拼接 $(q, z_i, a_{<t})$ 作为输入，生成器输出下一个 token 的分布：  
   $$
   (\text{batch\_size}, \text{vocab\_size})
   $$
   查找标准答案当前 token $a_t$ 的概率 $p_\theta(a_t \mid q, z_i, a_{<t})$。  
3. **边际化**：在 token 级别，对不同文档的概率加权求和：  
   $$
   p(a_t \mid q, a_{<t}) = \sum_{i=1}^K p_\eta(z_i \mid q) \cdot p_\theta(a_t \mid q, z_i, a_{<t})
   $$
4. **损失函数**：对每个 token 的综合概率取负对数，再对整个序列累加：  
   $$
   \mathcal{L} = - \sum_{t=1}^N \log p(a_t \mid q, a_{<t})
   $$
   同样，只更新查询编码器与生成器。

---

## 3. 对比总结

| 特性       | RAG-Sequence           | RAG-Token                    |
| ---------- | ---------------------- | ---------------------------- |
| 边际化位置 | 序列级（完整答案后）   | Token级（每个词）            |
| 概率公式   | $p(a                   | q) = \sum_i p(z_i            |
| 优点       | 计算更简单，速度快     | 更灵活，可融合多个文档的信息 |
| 缺点       | 假设整句来自同一文档   | 计算开销更大，训练更复杂     |
| 可训练模块 | 查询编码器、生成器     | 查询编码器、生成器           |
| 固定模块   | 文档编码器（通常固定） | 文档编码器（通常固定）       |

---

## 4. 总体结论
- **RAG-Sequence**：先选择一篇文档，再生成完整答案，边际化在序列级别。  
- **RAG-Token**：每个 token 都可能来自不同文档，边际化在 token 级别，更灵活但更耗算力。  
- 二者都不需要人工标注“正确文档”，仅依靠答案似然进行端到端训练。  

# 二、推理过程

RAG推理过程文字描述：

1、RAG-Sequence（候选答案级别的文档融合）：给定q，向量化所有文档和给定询问，计算内积，找到内积最大的k个文档作为非参数化内存；将查询q和每个文档拼接输入生成器，使用beam search生成beam size个候选答案（对每一个文档都使用beam search算法，最后每个文档得到beam size个候选答案），现在有k个文档生成的k\*beam_size个候选答案，并且每个候选答案可能出现在不同文档中（因为每个文档都会生成几个可能的答案，不同文档直接答案就可能有重复的，所有每个答案可能出现在不同文档的生成中），故而要计算每个答案的加权和（不同文档概率*这些文档自己的答案生成概率），选出加权和最大的答案，就是查询的输出。

2、RAG-Token（逐个token的生成和融合，标准的自回归过程）：给定询问q，向量化所有文档和给定询问，计算内积，找到内积最大的k个文档作为非参数化内存；初始化一个空的答案序列和一个beam search容器（里面有beam size个候选序列，初始为空序列）。在每一个时间步中，对于beam中的每一个候选序列，将当前候选序列、查询q和每一篇文档拼接，输入生成器，每一篇文档都会输出一个下一个token的 probability分布（形状是vocab_size）。由于同一个token可能由不同文档生成，故而用文档概率乘token生成概率，来计算加权和，得到一个融合了所有文档信息的、最终的下一个token概率分布。将这个最终的概率分布输入给beam search算法，beam search会根据这个分布来扩展候选序列和筛选出beam size个最可能的候选序列，更新beam中候选序列的内容。重复这个过程，直到beam search完成，最终输出得分最高的那个候选序列作为答案。

# RAG 推理流程总结

RAG 在推理阶段同样分为两种模式：**RAG-Sequence** 和 **RAG-Token**。  
区别在于：文档信息融合发生在 **序列级别** 还是 **token 级别**。

---

## 1. RAG-Sequence 推理流程

**输入**：一个查询 $q$  

**推理步骤**：
1. **文档检索**  
   - 使用查询编码器将 $q$ 向量化为 $\mathbf{q}$。  
   - 在索引库中通过最大内积搜索 (MIPS) 找到 Top-K 文档 $z_1, z_2, ..., z_K$。  
   - 每篇文档的检索概率为：  
     $$
     p_\eta(z_i \mid q) = \frac{\exp(\mathbf{q}^\top \mathbf{d}(z_i))}{\sum_j \exp(\mathbf{q}^\top \mathbf{d}(z_j))}
     $$

2. **独立生成**  
   - 对每个文档 $z_i$，拼接 $(q, z_i)$ 输入生成器。  
   - 使用 **beam search**，每个文档生成 `beam_size` 个候选答案。  
   - 最终得到 $K \times \text{beam\_size}$ 个候选答案（不同文档间可能出现重复答案）。  

3. **候选答案概率计算**  
   - 每个候选答案 $a$ 在文档 $z_i$ 下的生成概率：  
     $$
     p_\theta(a \mid q, z_i) = \prod_t p_\theta(a_t \mid q, z_i, a_{<t})
     $$
   - 如果同一答案 $a$ 出现在多个文档中，则整体概率通过文档加权融合：  
     $$
     p(a \mid q) = \sum_{i=1}^K p_\eta(z_i \mid q) \cdot p_\theta(a \mid q, z_i)
     $$

4. **答案选择**  
   
   - 对所有候选答案进行排序，选择概率最大的那个作为最终输出。  

---

## 2. RAG-Token 推理流程

**输入**：一个查询 $q$  

**推理步骤**：
1. **文档检索**  
   
- 与 RAG-Sequence 相同，使用查询编码器对 $q$ 向量化，并通过 MIPS 检索 Top-K 文档。  
   
2. **逐 token 自回归生成**  
   - 初始化 beam search 容器（大小为 `beam_size`），其中的候选序列初始为空。  
   - 在每一个时间步 $t$：  
     1. 对于 beam 中的每个候选序列 $a_{<t}$，将 $(q, z_i, a_{<t})$ 拼接输入生成器。  
     2. 每个文档 $z_i$ 会输出下一个 token 的分布：  
        $$
        p_\theta(\cdot \mid q, z_i, a_{<t})
        $$
     3. 对同一个候选 token $a_t$，融合所有文档的分布：  
        $$
        p(a_t \mid q, a_{<t}) = \sum_{i=1}^K p_\eta(z_i \mid q) \cdot p_\theta(a_t \mid q, z_i, a_{<t})
        $$
     4. 将融合后的分布作为下一步的概率分布，交给 beam search 扩展候选序列。  
     5. 保留得分最高的 `beam_size` 个候选序列。  

3. **终止条件**  
   
- 当 beam search 达到最大长度或生成结束符时，停止扩展。  
   
4. **答案选择**  
   
   - 从 beam 中选择最终得分最高的候选序列，作为输出答案。  

---

## 3. 总结
- **RAG-Sequence**：每个文档独立生成完整答案，最后在序列级别融合概率。  
- **RAG-Token**：在生成的每一个 token 位置，就对文档概率进行加权融合，beam search 始终运行在融合后的分布上。  
- 区别：RAG-Sequence 的文档融合发生在 **答案级**，RAG-Token 的文档融合发生在 **token 级**。  



