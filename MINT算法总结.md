# PPT汇报

LLM的局限 ---> RAG（框架图） ---> RAG的局限 ---> 两种局限+分别的解决尝试（图） ---> 引出MINT框架+贡献



理解 **基础任务 vs 辅助任务** 的区别

------

## 1. 基础任务（basic tasks）

- **数据来源**：**人工标注的真数据**（query–docid 对，query–answer 对）
- **目标**：让模型学会“最核心的能力”：
  - 检索器：给定真实 query → 找到相关 docid；
  - 生成器：给定真实 query + docid + 文档 → 生成答案。
- **训练方式**：标准的监督训练，基于最大似然估计（MLE）。
- **优点**：数据干净、可靠，模型直接学到“正确映射”。
- **缺点**：受限于标注数据规模，任务覆盖度不足。

------

## 2. 辅助任务（auxiliary tasks）

- **数据来源**：**大模型自动生成的伪数据**（pseudo-query、pseudo-triplet）
- **目标**：弥补标注数据不足，提升模型的“泛化性”和“鲁棒性”：
  - 检索器：
    1. (伪查询 → docid 排序) 让模型见识更多类型的问题；
    2. (docid → 相关 docid 排序) 让模型理解“文档之间的关系”。
  - 生成器：
     (伪查询 + 上下文 → 答案) 让模型学会“证据整合”，即使 query 的表达方式不同也能生成答案。
- **训练方式**：同样是 seq2seq + MLE，但目标是拟合伪答案。
- **优点**：数据量可以很大，能覆盖更多 query 形式和语境；
- **缺点**：伪数据质量可能不如人工标注，有一定噪声。

------

## 3. 关键区别总结

| 特性               | 基础任务                    | 辅助任务                           |
| ------------------ | --------------------------- | ---------------------------------- |
| **数据来源**       | 人工标注                    | LLM 自动生成                       |
| **任务形式**       | query–docid，query–answer   | pseudo-query–docid，pseudo-triplet |
| **目的**           | 学“核心能力”（检索 + 生成） | 扩展“表达多样性”和“鲁棒性”         |
| **数据质量**       | 高，但数量有限              | 质量可能有噪声，但数量大           |
| **在训练中的角色** | 主干                        | 辅助，增强泛化与稳定性             |

------

## 4. 你可以怎么讲给导师/同学

- **基础任务** = “主干” → 模型最基本的功夫；
- **辅助任务** = “补充练习” → 用 LLM 自动造题，让模型练习不同的提问方式和证据组合，提高适应力。

## 5.联合损失函数

- 整个 warm-up 阶段就是在最小化一个组合 loss：
  - LGRL_{GR}LGR：检索相关的损失（query → docid，document → docid）；
  - LRAGGL^{G}_{RAG}LRAGG：生成相关的损失（query+docid+document → 答案）；
  - LRAGAUXL^{AUX}_{RAG}LRAGAUX：辅助任务的损失（伪查询、伪三元组等）。
- 三个系数 λ1,λ2,λ3\lambda_1, \lambda_2, \lambda_3λ1,λ2,λ3 控制比例，比如要更注重检索，就把 λ1\lambda_1λ1 调大。





------

## 🔹 基础任务 vs 辅助任务的数据来源

1. **基础任务 (basic tasks)**
   - **数据来源**：**有标注的 QA 数据集**（比如 NQ、FEVER、HotpotQA 等）
   - **内容**：真实的 *query–answer–document* 对
   - **作用**：保证模型能在“金标准”上学到基本能力

------

1. **辅助任务 (auxiliary tasks)**
   - **数据来源**：**未标注的文档**
   - **做法**：用 Llama2-7B 加提示词 **自动生成伪数据**，比如：
     - **RAG 辅助任务**：
       - 伪查询（pseudo-query）
       - 三元组 (伪查询, 上下文, 答案)
       - 伪 docid 排序任务
     - **GAR 辅助任务**：
       - 伪查询 + 伪答案 (pseudo-query, pseudo-answer)
       - 检索器任务：伪查询+伪答案 → docid 排序
   - **作用**：扩大训练数据规模，让模型学到更多检索/生成模式（即使这些不是人工标注的）。

------

## 🔹 所以你的理解可以总结成一句话

- **基础任务** = 用人工标注数据来训练（质量高，但数量有限）。
- **辅助任务** = 从未标注文档里抽取 → 用 Llama2-7B 加提示 → 生成伪查询、伪答案、伪 docid → 拿来扩充训练（数量多，但质量参差，需要置信度筛选）。

------

## 🔹 结合前面的 MINT 思路

- Warm-up 阶段：
  - 基础任务（真数据）打底 → 确保模型不会跑偏
  - 辅助任务（伪数据）增强 → 提高泛化、拓展能力
- 协同训练阶段：
  - RAG 和 GAR 互相生成伪样本、再交换训练 → 进一步提升

------

✅ 总结：
 是的，**辅助任务确实是用未标注的文档，通过 Llama2-7B + prompt 自动生成伪数据**。这样模型就能在真实数据有限的情况下，依然获得大规模的训练信号。





------

## 🔹 辅助任务用的未标注文档

- 在 **warm-up 阶段**（RAG/GAR 各自单独训练时）：
  - 需要给模型额外训练信号；
  - 所以从 **未标注语料库** 中抽取文档；
  - 再通过 **Llama2-7B + 提示** 生成伪查询、伪答案、伪 docid 排序等 → 构造成伪数据；
  - 这些数据用于 **辅助任务的 loss (LAUX)**。

👉 辅助任务主要是 **LLM（外部）帮助造数据**。

------

## 🔹 协同训练用的未标注文档

- 在 **co-training 阶段**（RAG 与 GAR 互相教学时）：
  - 也会从 **未标注语料库** 里选取文档（记为 D−D^{-}）；
  - 不过这次是直接由 **RAG 和 GAR 自己生成伪样本** (伪查询, docids, 答案)；
  - 再经过置信度筛选 → 交换使用 → 互相训练。

👉 协同训练主要是 **模型自己生成伪数据**。

------

## 🔹 是否同一批文档？

- **可以是同一个未标注语料库**（比如维基百科、CC-News 之类的大规模语料），这是最常见做法。
- 但在不同阶段：
  - **辅助任务**：更多是 *warm-up 阶段* 用 Llama2-7B 造伪数据。
  - **协同训练**：更多是 *co-training 阶段* 用 RAG/GAR 自己生成伪数据。

换句话说，**数据池可以相同，但生成伪数据的“责任人”不同**：

- 辅助任务：外部 LLM（Llama2-7B） → 给模型打辅助。
- 协同训练：RAG & GAR 本身 → 互相教学。

------

✅ 总结一句话：
 辅助任务和协同训练用的未标注文档 **可以来自同一批语料**，但 **伪数据的生成方式不同**：

- 辅助任务靠 **外部 LLM** 生成；
- 协同训练靠 **RAG/GAR 自身** 生成并互换。





---

## 训练流程

```bash
                ┌───────────┐
                │ 标注数据  │
                └─────┬─────┘
                      │
        ┌─────────────┼─────────────┐
        │                               │
   Warm-up RAG                     Warm-up GAR
 (θ0: 检索+生成)                (ψ0: 生成+检索)
        │                               │
        └─────────────┬─────────────┘
                      │
              未标注数据 D-
                      │
           ┌──────────┴──────────┐
           │                                 │
    RAG 生成伪样本 D0_RAG         GAR 生成伪样本 D0_GAR
           │                                 │
           └─────→ 置信度筛选 ←──────┘
                      │
         ┌────────────┴────────────┐
         │                         │
   用 D0_GAR 训练 RAG        用 D0_RAG 训练 GAR
   (θ0 → θ1)                   (ψ0 → ψ1)
         │                         │
         └─────→ 迭代更新 ←──────┘
                      │
                收敛得到 (θT, ψT)

```





------

## 🔹 1. 普通 RAG / DPR / dense retrieval 的情况

- 它们需要 **保存一个大规模稠密文档索引**：
  - 每个文档都会转成一个向量 embedding（比如 768 维）。
  - 所有文档向量组成一个巨大的矩阵。
  - 检索时，query embedding 和这个矩阵做最近邻搜索。
- 缺点：
  - 存储占用非常大（比如上亿个向量）。
  - 查询延迟高，因为需要在大矩阵里做 ANN 搜索。

------

## 🔹 2. MINT 的做法

MINT 不是保存向量索引，而是：

- **用 docid 表示文档**（这里 docid = Wikipedia 的 **文档标题**）。
- 模型直接在 **生成空间里输出 docid**，而不是做 embedding 匹配。
- 所以：
  - 只需要保存 **文档标题**，而不是存储庞大的稠密向量库。
  - 内存消耗骤减（论文里说比 MT-DPR+FID 少 201.2 倍）。

------

## 🔹 3. 和 CorpusLM 的区别

- **MINT**：只存 **文档标题**（title）作为 docid。
- **CorpusLM**：存 **文档标题 + 分节标题**（section title），因为它在 finer-grained 的粒度上检索。
- 所以 CorpusLM 内存占用比 MINT 大。

------

## 🔹 4. 回答你的问题

> **所以模型只保存文档索引吗？**

更准确地说：

- **传统 RAG / DPR** 保存的是 **稠密向量索引**（大规模 embedding 矩阵）。
- **MINT** 只保存 **docid（Wikipedia 标题字符串）**，不需要保存 embedding 索引。

这就是为什么 MINT 的内存占用能下降几个数量级。

------

✅ 一句话总结：
 **MINT 不保存稠密文档向量索引，只保存 docid（文档标题），然后通过生成式检索直接输出 docid 来定位文档。**





